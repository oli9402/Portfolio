{
  "hash": "432dd894c770fe2462b34b8260d7139d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Accuracy of selected predictors per sample size\"\ndate: \"2022-10-10\"\ndate-modified: \"11/20/2024\"\nauthors: \"Oliver Zingg, M. P. , C. B.\" \nimage: \"jacksonj.jpg\"\n---\n\n\nWith this exercise we want to inspect how **lm function** and **step function** vary when it comes to selection of  correct variables depending on sample size.\n\nFoto von <a href=\"https://unsplash.com/de/@jacksonjost?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Jackson Jost</a> auf <a href=\"https://unsplash.com/de/fotos/tjKSTwb4mnI?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash\">Unsplash</a>\n\n\n\n## Generate Data\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages \nlibrary(lme4)\nlibrary(dplyr)\nlibrary(ggplot2)\n\noptions(scipen=0)\nset.seed(101)\n\n# Variable and Dataset preparation\nN <- c(25, 30, 40, 60, 100 ,500, 1000)\n# create a data frame to later add which variables were selected \npredi_selection_lm <- as.data.frame(matrix(NA, nrow = 19, ncol = length(N)))\npredi_selection_step <- as.data.frame(matrix(NA, nrow = 19, ncol = length(N)))\n\nnames(predi_selection_lm ) <- c(\"N25\", \"N30\", \"N40\", \"N60\", \"N100\", \"N500\", \"N1000\")\nnames(predi_selection_step ) <- c(\"N25\", \"N30\", \"N40\", \"N60\", \"N100\", \"N500\", \"N1000\")\n\n#counter to use as index for table predi_selection (loop)\na = 1\n\n#loop over different N (sample size)\nfor(i in N){\n  # Simulation dataset\n  x1 <- runif(i, 0, 10)\n  x2 <- runif(i, 0, 10)\n  x3 <- runif(i, 0, 10)\n  x4 <- runif(i, 0, 10)\n  x5 <- runif(i, 0, 10)\n  x6 <- runif(i, 0, 10)\n  x7 <- runif(i, 0, 10)\n  x8 <- runif(i, 0, 10)\n  x9 <- runif(i, 0, 10)\n  x10 <- runif(i, 0, 10)\n  x11 <- runif(i, 0, 10)\n  x12 <- runif(i, 0, 10)\n  x13 <- runif(i, 0, 10)\n  x14 <- runif(i, 0, 10)\n  x15 <- runif(i, 0, 10)\n  x16 <- runif(i, 0, 10)\n  x17 <- runif(i, 0, 10)\n  x18 <- runif(i, 0, 10)\n  x19 <- runif(i, 0, 10)\n  err <- runif(i, 0, 5)\n  \n  data <- cbind(x1,x2,x3,x4,x5,x6, x7, x8, x9 ,x10, x11, x12, x13, x14, x15, x16, x17, x18, x19,  err)\n  data <- as.data.frame(data)\n \n  # generate y values.\n  y <- 30 + 0.4*x1 + 1*x2 + 2.3*x3 + 0.7*x4 + 0.2*x5  + 1*x6 + 2*x7 + 3*x8 + 1.5 *x9 + 0.5*x10 + err\n  \n  # add generated y values to data frame\n  data_2 <- cbind(data, y)\n  \n  # Modelling with all variables as predi.\n  mod <- lm(y~ x1 + x2 + x3 + x4 + x5 + x5 +x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19, data =  data_2)\n  summary(mod)\n  \n  ########################\n  #lets try step function#\n  ########################\n \n\n  # use step function and save final model as stepwise_model\n  stepwise_model <-  step(mod)\n\n  \n  # Extract p-val: lm\n  p_val_lm <- (summary(mod)$coefficients[,4])\n  p_val_lm <- p_val_lm[2:20] #take out intercept\n  \n  # Extract p-val: step\n  p_val_step <- summary(stepwise_model)$coefficients[,4]\n  p_val_step <- p_val_step[2:20] #take out intercept\n  \n  # Store value: lm \n  predi_selection_lm[a] <- ifelse(p_val_lm < 0.05, 1, 0)\n  \n  #store values for step different, because summary output dosen't include all variable like in lm \n  p_val_step <-  na.omit(ifelse(p_val_step < 0.05, 1, 0))\n \n   #remove selected pred. without 0.05\n  p_val_step <- p_val_step[! p_val_step %in% 0]\n  \n  # save the names of all selected coefficients as coes\n  coes <- names(p_val_step)\n  \n  # create dummy var with all possible variables \n  dummy_var <- c('x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12','x13','x14','x15','x16','x17','x18','x19')\n  \n  # which out of all possible variable have been selected? \n  selected_coe <- ifelse(dummy_var %in% coes, 1,0)\n  \n  predi_selection_step[a] <- selected_coe\n  \n  #increase counter by one\n  a = a + 1\n}\n\n# Summary accuracy predictors selection\ntrue_pred_dummy <- c(1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0) #dummy code for the existing predictor \n\n# new data frame to compare true predi. to selected predi.\npredi_accuracy_lm <- data.frame(matrix(NA, nrow = 19, ncol = length(N)))\nnames(predi_accuracy_lm) <- c(\"N25\", \"N30\", \"N40\", \"N60\", \"N100\", \"N500\", \"N1000\")\n\npredi_accuracy_step <- data.frame(matrix(NA, nrow = 19, ncol = length(N)))\nnames(predi_accuracy_step) <- c(\"N25\", \"N30\", \"N40\", \"N60\", \"N100\", \"N500\", \"N1000\")\n\n#if all correct than coloumn all 1. \nfor (j in 1:length(N)){\n  predi_accuracy_lm[j] <- ifelse(predi_selection_lm[j] == true_pred_dummy, 1,0)\n  predi_accuracy_step[j] <- ifelse(predi_selection_step[j] == true_pred_dummy, 1,0)\n}\n```\n:::\n\n\n## Now lets visualize these results \n\n::: {.cell}\n\n```{.r .cell-code}\n# final data frame used for visualization\nsample_s <- c(\"N25\", \"N30\", \"N40\", \"N60\", \"N100\", \"N500\", \"N1000\")\nsummary_accuracy <- data.frame(cbind(sample_s,rep(NA, times = length(sample_s)),rep(NA, times = length(sample_s))))\nnames(summary_accuracy) <- c(\"sample_s\", \"accuracy_lm\", \"accuracy_step\")\n\n\n\nfor( i in 1: nrow(summary_accuracy)){\n  summary_accuracy[i,2] <-  mean(predi_accuracy_lm[,i])\n  summary_accuracy[i,3] <-  mean(predi_accuracy_step[,i])\n\n}\nsummary_accuracy$accuracy_lm <- as.numeric(summary_accuracy$accuracy_lm)\nsummary_accuracy$accuracy_step <- as.numeric(summary_accuracy$accuracy_step)\nggplot(data = summary_accuracy,aes(x=factor(sample_s, \n                                           level = c(\"N25\", \"N30\", \"N40\", \"N60\", \"N100\", \"N500\", \"N1000\")) ,\n                                            y = accuracy_lm)) + \n  geom_bar(stat= \"identity\")+\n  xlab(\"sample size\")+\n  labs(title = \"Accuracy of selected predictor per sample size\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\nThis is the accuracy of the **normal lm function** with all predictors used.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = summary_accuracy,aes(x=factor(sample_s, \n                                           level = c(\"N25\", \"N30\", \"N40\", \"N60\", \"N100\", \"N500\", \"N1000\")) ,\n                                            y = accuracy_step)) + \n  geom_bar(stat= \"identity\")+\n  xlab(\"sample size\")+\n  labs(title = \"Accuracy of selected predictor per sample size\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThis is the accuracy of the **step function** default = backwards selection (starting with full model: all predictors) .\n\n## Summary:\n\n* especially with low sample size N25 step function seems to perform less well than normal lm function\n* with increasing sample size both perform well and use all relevant predictors \n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}